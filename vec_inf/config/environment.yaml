paths:
  # NOTE: ld_library_path and vllm_nccl_so_path may be leftover code and not really used
  # If you want to remove them, you need to modify _slurm_vars.py, _slurm_templates.py, and _slurm_script_generator.py
  ld_library_path: "/scratch/ssd001/pkgs/cudnn-11.7-v8.5.0.96/lib/:/scratch/ssd001/pkgs/cuda-11.7/targets/x86_64-linux/lib/"
  image_path: "/cluster/projects/gliugroup/2BLAST/containers/vec-inf-image-2025-05-15.sif"
  vllm_nccl_so_path: "/vec-inf/nccl/libnccl.so.2.18.1"

containerization:
  module_load_cmd: "module load singularity/3.11.0"
  module_name: "singularity"

limits:
  max_gpus_per_node: 8
  max_num_nodes: 16
  max_cpus_per_task: 128

allowed_values:
  # Quality of Service (QoS) options for Slurm jobs
  # Don't think H4H supports these, so just ignore them
  qos: ["normal", "m", "m2", "m3", "m4", "m5", "long", "deadline", "high", "scavenger", "llm", "a100"]
  partition: ["gpu"]

default_args:
  cpus_per_task: 16
  mem_per_node: "64G"
  qos: "m2"
  time: "08:00:00"
  partition: "gpu"
  data_type: "auto"
  log_dir: "~/.vec-inf-logs"
  model_weights_parent_dir: "/cluster/projects/gliugroup/2BLAST/LLMs"
  bind: ",~/"
