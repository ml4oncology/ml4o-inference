models:
  Mistral-7B-Instruct-v0.3:
    model_family: Mistral
    model_variant: 7B-Instruct-v0.3
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32768
    qos: m2
    time: 08:00:00
    partition: gpu
    account: gliugroup_gpu
    model_weights_parent_dir: /cluster/projects/gliugroup/2BLAST/LLMs
    vllm_args:
      --max-model-len: 32768
      --max-num-seqs: 256
      --compilation-config: 3