models:
  Meta-Llama-3.1-70B-Instruct:
    model_family: Meta-Llama-3.1
    model_variant: 70B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    qos: m2
    time: 08:00:00
    partition: gpu
    account: grantgroup_gpu
    model_weights_parent_dir: "/cluster/projects/gliugroup/2BLAST/LLMs"
    bind: "~"
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 65536
      --max-num-seqs: 256
      --compilation-config: 3
  Meta-Llama-3.1-8B-Instruct:
    model_family: Meta-Llama-3.1
    model_variant: 8B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    qos: m2
    time: 08:00:00
    partition: gpu
    account: grantgroup_gpu
    model_weights_parent_dir: "/cluster/projects/gliugroup/2BLAST/LLMs"
    bind: "~"
    vllm_args:
      --max-model-len: 131072
      --max-num-seqs: 256
      --compilation-config: 3
  Mistral-7B-Instruct-v0.3:
    model_family: Mistral
    model_variant: 7B-Instruct-v0.3
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32768
    qos: m2
    time: 08:00:00
    partition: gpu
    account: grantgroup_gpu
    model_weights_parent_dir: "/cluster/projects/gliugroup/2BLAST/LLMs"
    bind: "~"
    vllm_args:
      --max-model-len: 32768
      --max-num-seqs: 256
      --compilation-config: 3
  Qwen2.5-14B-Instruct-IQ4_XS.gguf:
    model_family: Qwen2.5-14B-Instruct-IQ4_XS
    model_variant: IQ4_XS
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    qos: m2
    time: 08:00:00
    partition: gpu
    account: grantgroup_gpu
    model_weights_parent_dir: "/cluster/projects/gliugroup/2BLAST/LLMs"
    bind: "~"
    vllm_args:
      # --tokenizer: /cluster/projects/gliugroup/2BLAST/LLMs/Qwen2.5-14B-Instruct
      --max-model-len: 32768
      --max-num-seqs: 256
  Qwen2.5-14B-Instruct:
    model_family: Qwen2.5
    model_variant: 14B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    qos: m2
    time: 08:00:00
    partition: gpu
    account: grantgroup_gpu
    model_weights_parent_dir: "/cluster/projects/gliugroup/2BLAST/LLMs"
    bind: "~"
    vllm_args:
      --max-model-len: 32768
      --max-num-seqs: 256